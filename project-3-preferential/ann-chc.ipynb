{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearGreaterThanZero(nn.Linear):\n",
    "    def __init__(self, in_features, bias=False, min_w=0.0000001):\n",
    "        super().__init__(in_features, 1, bias)\n",
    "        self.is_bias = bias\n",
    "        self.min_w = min_w\n",
    "        if bias:\n",
    "            nn.init.uniform_(self.bias, self.min_w, 1.0)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.weight, 0.1, 1.0)\n",
    "\n",
    "    def w(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight.data[self.weight.data < 0] = self.min_w\n",
    "        return self.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.w(), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearInteraction(nn.Linear):\n",
    "    def __init__(self, in_features, criterion_layer):\n",
    "        super().__init__(((in_features - 1) * in_features) // 2, 1, False)\n",
    "        self.in_features = in_features\n",
    "        self.criterion_layer = criterion_layer\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, 0.0, 0.1)\n",
    "\n",
    "    def w(self):\n",
    "        with torch.no_grad():\n",
    "            w_i = 0\n",
    "            w = self.criterion_layer.w()\n",
    "            for i in range(self.in_features):\n",
    "                for j in range(i + 1, self.in_features):\n",
    "                    self.weight.data[:, w_i] = torch.max(\n",
    "                        self.weight.data[:, w_i], -w[:, i]\n",
    "                    )\n",
    "                    self.weight.data[:, w_i] = torch.max(\n",
    "                        self.weight.data[:, w_i], -w[:, j]\n",
    "                    )\n",
    "                    w_i += 1\n",
    "        return self.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.w(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdLayer(nn.Module):\n",
    "    def __init__(self, threshold=None, requires_grad=True):\n",
    "        super().__init__()\n",
    "        if threshold is None:\n",
    "            self.threshold = nn.Parameter(\n",
    "                torch.FloatTensor(1).uniform_(0.1, 0.5), requires_grad=requires_grad\n",
    "            )\n",
    "        else:\n",
    "            self.threshold = nn.Parameter(\n",
    "                torch.FloatTensor([threshold]), requires_grad=requires_grad\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x - self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoquetConstrained(nn.Module):\n",
    "    def __init__(self, criteria_nr, **kwargs):\n",
    "        super().__init__()\n",
    "        self.criteria_nr = criteria_nr\n",
    "        self.criteria_layer = LinearGreaterThanZero(criteria_nr)\n",
    "        self.interaction_layer = LinearInteraction(criteria_nr, self.criteria_layer)\n",
    "        self.thresholdLayer = ThresholdLayer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, 0, :]\n",
    "        x_wi = self.criteria_layer(x[:, : self.criteria_nr])\n",
    "        x_wij = self.interaction_layer(x[:, self.criteria_nr :])\n",
    "        weight_sum = self.criteria_layer.w().sum() + self.interaction_layer.w().sum()\n",
    "        score = (x_wi + x_wij) / (weight_sum)\n",
    "        return self.thresholdLayer(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobious_transform(row):\n",
    "    return list(row) + [\n",
    "        min(row[i], row[j]) for i in range(len(row)) for j in range(i + 1, len(row))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy._typing import NDArray\n",
    "from typing import ClassVar\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "@dataclass\n",
    "class Dataset(object):\n",
    "  train: DataFrame\n",
    "  test: DataFrame\n",
    "  _encoder: ClassVar[OneHotEncoder] = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "  @classmethod\n",
    "  def load(cls):\n",
    "    return cls(\n",
    "      pd.read_csv(f\"./resources/datasets/loan_sanction_train.csv\"),\n",
    "      pd.read_csv(f\"./resources/datasets/loan_sanction_test.csv\")\n",
    "    )\n",
    "\n",
    "  def preprocess(self, split: str) -> tuple[NDArray, NDArray | None]:\n",
    "    if split == 'train':\n",
    "      df = self.train.copy()\n",
    "      df.dropna(inplace=True)\n",
    "      df.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "      X = df.drop(columns=[\"Loan_Status\"])\n",
    "      y = df[\"Loan_Status\"]\n",
    "\n",
    "      X = self._encoder.fit_transform(X)\n",
    "      y = y.map({\"N\": 0, \"Y\": 1})\n",
    "\n",
    "      return X, y\n",
    "    df = self.test.copy()\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "    X = self._encoder.transform(df)\n",
    "\n",
    "    return X\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Dataset.load().preprocess('train')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = CreateDataLoader(X_train, y_train)\n",
    "test_dataloader = CreateDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"choquet.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChoquetConstrained(criteria_nr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:10<00:00, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:\t80.38%\n",
      "AUC train: \t81.00%\n",
      "\n",
      "Accuracy test:\t79.95%\n",
      "AUC test: \t81.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc, acc_test, auc, auc_test = Train(model, train_dataloader, test_dataloader, PATH)\n",
    "\n",
    "print(\"Accuracy train:\\t%.2f%%\" % (acc * 100.0))\n",
    "print(\"AUC train: \\t%.2f%%\" % (acc_test * 100.0))\n",
    "print()\n",
    "print(\"Accuracy test:\\t%.2f%%\" % (auc * 100.0))\n",
    "print(\"AUC test: \\t%.2f%%\" % (auc_test * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.criteria_layer.w().detach().numpy()[0]\n",
    "interaction_weights = model.interaction_layer.w().detach().numpy()[0]\n",
    "s = weights.sum() + interaction_weights.sum()\n",
    "weights = weights / s\n",
    "interaction_weights = interaction_weights / s\n",
    "\n",
    "interactions = np.zeros((criteria_nr, criteria_nr))\n",
    "weight_id = 0\n",
    "for i in range(criteria_nr):\n",
    "    for j in range(i + 1, criteria_nr):\n",
    "        interactions[i, j] = interactions[j, i] = interaction_weights[weight_id]\n",
    "        weight_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria weights:\n",
      "[0.18973008 0.13305973 0.21117473 0.1774406 ]\n",
      "\n",
      "Criteria interactions:\n",
      "[[0.         0.05106746 0.02530925 0.1322839 ]\n",
      " [0.05106746 0.         0.00588444 0.04943791]\n",
      " [0.02530925 0.00588444 0.         0.02461192]\n",
      " [0.1322839  0.04943791 0.02461192 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Criteria weights:\")\n",
    "print(weights)\n",
    "print()\n",
    "print(\"Criteria interactions:\")\n",
    "print(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of criterina (Shapley value):\n",
      "[0.29406038 0.18625463 0.23907753 0.28060746]\n"
     ]
    }
   ],
   "source": [
    "shapley = weights + interactions.sum(0) / 2\n",
    "print(\"Importance of criterina (Shapley value):\")\n",
    "print(shapley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
